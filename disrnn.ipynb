{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled RNN Analysis\n",
    "In this notebook, you can see how the latent variables are maintained inside the disentangled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import disrnn\n",
    "from src import switch_utils\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/\"\n",
    "\n",
    "# choose mouse, beta and run time\n",
    "train_prop = 0.7\n",
    "param = 0.003\n",
    "cv = f'{train_prop*100:.0f}-{(1-train_prop)*100:.0f}'\n",
    "train_dt = \"2025-04-10_12-51\"\n",
    "batch_size = 30\n",
    "\n",
    "model_shape = {'dis_latent_size': 5,\n",
    "                'update_mlp_shape': (5,5,5),\n",
    "                'choice_mlp_shape': (2,2),\n",
    "                'obs_size': 2,\n",
    "                'target_size': 2}\n",
    "\n",
    "params_file = os.path.join(model_dir, f\"params_{param:.0e}_{cv}_{train_dt}.json\")\n",
    "params = switch_utils.model_loader(params_file=params_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval mode runs the network with no noise\n",
    "def make_network_eval():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=model_shape['update_mlp_shape'],\n",
    "                        choice_mlp_shape=model_shape['choice_mlp_shape'],\n",
    "                        latent_size=model_shape['dis_latent_size'],\n",
    "                        obs_size=2, \n",
    "                        target_size=2,\n",
    "                        eval_mode=True)\n",
    "\n",
    "\n",
    "disrnn.plot_bottlenecks(params, sort_latents=True)\n",
    "plt.show()\n",
    "disrnn.plot_update_rules(params, make_network_eval)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/params_3e-03_70-30_2025-04-18_00-24.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     24\u001b[39m df_tr = pd.read_csv(os.path.join(data_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain_df_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_dt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     25\u001b[39m df_va = pd.read_csv(os.path.join(data_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalidation_df_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit_dt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m params, losses = \u001b[43mswitch_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m ds_tr = switch_utils.get_dataset(df_tr, batch_size)\n\u001b[32m     30\u001b[39m ds_va = switch_utils.get_dataset(df_va, batch_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspaces/pbm_group2/disentangled_rnns/src/switch_utils.py:81\u001b[39m, in \u001b[36mmodel_loader\u001b[39m\u001b[34m(params_file, loss_file)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_loader\u001b[39m(params_file, loss_file=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     77\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[33;03m  Loads model parameters and training loss from a JSON file saved with NpEncoder\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m  and converts lists back to JAX arrays.\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     82\u001b[39m     params_raw = json.load(f)\n\u001b[32m     83\u001b[39m   params = rnn_utils.to_jnp(params_raw)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/params_3e-03_70-30_2025-04-18_00-24.json'"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/data/processed'\n",
    "model_dir = \"/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/\"\n",
    "\n",
    "# choose mouse, beta and run time\n",
    "model_name = 'disrnn'\n",
    "train_prop = 0.7\n",
    "param = 0.003\n",
    "cv = f'{train_prop*100:.0f}-{(1-train_prop)*100:.0f}'\n",
    "train_dt = \"2025-04-18_00-24\"\n",
    "split_dt = \"2025-04-17_10-28\"\n",
    "batch_size = 64\n",
    "\n",
    "model_shape = {'dis_latent_size': 5,\n",
    "                'tiny_latent_size': 2,\n",
    "                'update_mlp_shape': (5,5,5),\n",
    "                'choice_mlp_shape': (2,2),\n",
    "                'obs_size': 2,\n",
    "                'target_size': 2}\n",
    "\n",
    "param_dict = {'disrnn': f'{param:.0e}', 'rnn': f'{param}'}\n",
    "params_file = os.path.join(model_dir, f\"params_{model_name}_{param_dict[model_name]}_{cv}_{train_dt}.json\")\n",
    "loss_file = os.path.join(model_dir, f\"loss_{model_name}_{param_dict[model_name]}_{cv}_{train_dt}.csv\")\n",
    "\n",
    "df_tr = pd.read_csv(os.path.join(data_dir, f\"train_df_{cv}_{split_dt}.csv\"))\n",
    "df_va = pd.read_csv(os.path.join(data_dir, f\"validation_df_{cv}_{split_dt}.csv\"))\n",
    "\n",
    "params, losses = switch_utils.model_loader(params_file=params_file, loss_file=loss_file)\n",
    "\n",
    "ds_tr = switch_utils.get_dataset(df_tr, batch_size)\n",
    "ds_va = switch_utils.get_dataset(df_va, batch_size)\n",
    "\n",
    "\n",
    "def make_network_eval():\n",
    "    return disrnn.HkDisRNN(update_mlp_shape=model_shape['update_mlp_shape'],\n",
    "                            choice_mlp_shape=model_shape['choice_mlp_shape'],\n",
    "                            latent_size=model_shape['dis_latent_size'],\n",
    "                            obs_size=model_shape['obs_size'], \n",
    "                            target_size=model_shape['target_size'],\n",
    "                            eval_mode=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disrnn.plot_bottlenecks(params, sort_latents=True)\n",
    "plt.show()\n",
    "disrnn.plot_update_rules(params, make_network_eval)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
