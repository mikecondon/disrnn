{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled RNNs for Mouse Switching Dataset\n",
    "The dataset below is from [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/7E0NM5). Each row corresponds to a trial, and the columns correspond to the trial number, block position, target direction, choice direction, and reward outcome, as well as the session and mouse identifiers and task conditions.\n",
    "\n",
    "| Trial | blockTrial | Decision | Switch | Reward | Condition | Target | blockLength | Session | Mouse |\n",
    "|-------|------------|----------|--------|--------|-----------|--------|-------------|---------|-------|\n",
    "| 11.0  | 11.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |\n",
    "| 12.0  | 12.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |\n",
    "| 13.0  | 13.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangled_rnns.library import rnn_utils\n",
    "from disentangled_rnns.library import disrnn\n",
    "from disentangled_rnns import switch_utils\n",
    "import optax\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "addr = \"/Users/michaelcondon/workspaces/pbm_group2/2ABT_behavior_models/bandit_data.csv\"\n",
    "batch_size = 30\n",
    "df = pd.read_csv(addr)\n",
    "\n",
    "# choose only 80-20 condition\n",
    "df = df[df['Condition'] == '80-20']\n",
    "eps = df['Session'].value_counts().sample(frac=1)\n",
    "\n",
    "# create training and validation datasets with a 70% train 30% validation split\n",
    "tr_eps = eps.iloc[:math.floor(0.7*len(eps))]\n",
    "ds_tr = switch_utils.get_dataset(df[df['Session'].isin(tr_eps.index)], batch_size)\n",
    "\n",
    "va_eps = eps.iloc[math.floor(0.7*len(eps)):]\n",
    "ds_va = switch_utils.get_dataset(df[df['Session'].isin(tr_eps.index)], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_mlp_shape = (5,5,5)\n",
    "choice_mlp_shape = (2,2)\n",
    "latent_size = 5\n",
    "\n",
    "def make_network():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "opt = optax.adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterate through the mice, and through the beta values, saving the trained\n",
    "params and loss for each in a json to disk.\n",
    "\"\"\"\n",
    "# betas = [1e-3, 3e-3, 1e-2, 3e-2]\n",
    "betas = [1e-3]\n",
    "n_steps = 1e2\n",
    "\n",
    "n_calls = len(betas)\n",
    "dt = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "print(f\"start time: {dt}\")\n",
    "with tqdm(total=n_calls, desc='Overall Progress', position=1) as outer_bar:\n",
    "  for beta_j in betas:\n",
    "    outer_bar.set_postfix(beta=f\"{beta_j:.0e}\")\n",
    "    params, opt_state, losses = rnn_utils.train_network(\n",
    "    make_network,\n",
    "        ds_tr,\n",
    "        ds_va,\n",
    "        ltype_tr=\"penalized_categorical\",\n",
    "        opt = optax.adam(learning_rate),\n",
    "        penalty_scale = beta_j,\n",
    "        n_steps=n_steps,\n",
    "        do_plot = False)\n",
    "    switch_utils.model_saver(params, beta_j, dt=dt, loss=losses)\n",
    "    outer_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "From here on, you can load models from disk for each mouse as trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = \"/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/\"\n",
    "\n",
    "# choose mouse, beta and run time\n",
    "mouse = \"m2\"\n",
    "beta = 0.001\n",
    "cv = 0\n",
    "dt = \"2025-04-09_18-18\"\n",
    "\n",
    "\n",
    "params_file = os.path.join(directory, f\"params_{beta:.0e}_0_{dt}.json\")\n",
    "loss_file = os.path.join(directory, f\"loss_{beta:.0e}_0_{dt}.json\")\n",
    "\n",
    "params, loss = switch_utils.model_loader(params_file=params_file, loss_file=loss_file)\n",
    "training_loss = loss['training_loss']\n",
    "validation_loss = loss['validation_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(training_loss, color='black')\n",
    "plt.semilogy(np.linspace(0, len(training_loss), len(validation_loss)), validation_loss, color='tab:red', linestyle='dashed')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.legend(('Training Set', 'Validation Set'))\n",
    "plt.title('Loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval mode runs the network with no noise\n",
    "def make_network_eval():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2,\n",
    "                        eval_mode=True)\n",
    "\n",
    "\n",
    "disrnn.plot_bottlenecks(params, sort_latents=True)\n",
    "plt.show()\n",
    "disrnn.plot_update_rules(params, make_network_eval)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Analysis\n",
    "Here I will check how the RNN models from above behave from a switching perspective. This is based on the comparisons from the paper:\n",
    "\n",
    "    Beron, C. C., Neufeld, S. Q., Linderman, S. W., & Sabatini, B. L. (2022). Mice exhibit stochastic and efficient action switching during probabilistic decision making. Proceedings of the National Academy of Sciences, 119(15), e2113961119. https://doi.org/10.1073/pnas.2113961119\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterate through each session of each dataset.\n",
    "\"\"\"\n",
    "import itertools\n",
    "import disentangled_rnns.switch_utils as switch_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "addr = \"/Users/michaelcondon/workspaces/pbm_group2/2ABT_behavior_models/bandit_data.csv\"\n",
    "# dataset with no division into training set etc\n",
    "full_ds = switch_utils.get_dataset(addr, tr_prop=1.0, condition='80-20')\n",
    "dss = [full_ds[i][1]._xs for i in range(len(full_ds))]\n",
    "ds = dss[1]\n",
    "\n",
    "chars = 'lrLR'\n",
    "h_len = 3\n",
    "seq_dict = {''.join(seq): [0,0] for seq in itertools.product(chars, repeat=3)}\n",
    "\n",
    "for session_i in range(np.shape(ds)[1]):\n",
    "  session = ds[:, session_i]\n",
    "  for ts_i in range(3, np.shape(session)[0]):\n",
    "    if session[ts_i, 0] == -1:\n",
    "      break\n",
    "    ts = session[ts_i-3: ts_i]\n",
    "    key = ''.join([chars[int(a+2*b)] for a, b in ts])\n",
    "    if session[ts_i, 0] == session[ts_i-1, 0]:\n",
    "      seq_dict[key][0] += 1\n",
    "    else:\n",
    "      seq_dict[key][1] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(t1):\n",
    "  print(t1)\n",
    "  if t1 == [0, 0]:\n",
    "    return 0\n",
    "  return t1[1] / (t1[0]+t1[1])\n",
    "\n",
    "p_dict = {key: mean(val) for key, val in seq_dict.items()}\n",
    "\n",
    "eq_chars = 'aAbB'\n",
    "eqs = list(itertools.product(eq_chars, repeat=h_len))[:len(eq_chars)**h_len//2]\n",
    "eq_dict = {''.join(seq): 0 for seq in eqs}\n",
    "for seq in eq_dict:\n",
    "  tran1 = seq.translate(str.maketrans('abAB', 'lrLR'))\n",
    "  tran2 = seq.translate(str.maketrans('abAB', 'rlRL'))\n",
    "  eq_dict[seq] = (p_dict[tran1] + p_dict[tran2]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sorted_items = sorted(eq_dict.items(), key=lambda item: item[1])\n",
    "sorted_labels = [item[0] for item in sorted_items]\n",
    "sorted_heights = [item[1] for item in sorted_items]\n",
    "total_height = sum(sorted_heights)\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.7, rc={'axes.labelsize':20, 'axes.titlesize':20})\n",
    "sns.set_palette('deep')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,4.2))\n",
    "\n",
    "sns.barplot(x=sorted_labels, y=sorted_heights, color='k', alpha=0.5, ax=ax, edgecolor='gray')\n",
    "ax.errorbar(x=sorted_labels, y=sorted_heights, fmt=' ', color='k', label=None)\n",
    "\n",
    "ax.set(xlim=(-1,len(sorted_heights)), ylim=(0,1), ylabel='P(switch)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine()\n",
    "plt.title('Empirical Switch Probabilities')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ds_list[1][2]._xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def make_network_eval():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2,\n",
    "                        eval_mode=True)\n",
    "\n",
    "def unroll_network(xs):\n",
    "  core = make_network()\n",
    "  batch_size = jnp.shape(xs)[1]\n",
    "  state = core.initial_state(batch_size)\n",
    "  ys, _ = hk.dynamic_unroll(core, xs, state)\n",
    "  return ys\n",
    "\n",
    "\n",
    "\n",
    "# Haiku, step two: Transform the network into a pair of functions\n",
    "# (model.init and model.apply)\n",
    "_, step_hk = hk.transform(unroll_network)\n",
    "step_hk = jax.jit(step_hk)\n",
    "\n",
    "random_key = jax.random.PRNGKey(0)\n",
    "# If params have not been supplied, start training from scratch\n",
    "random_key, key1 = jax.random.split(random_key)\n",
    "\n",
    "\n",
    "xs, ys = full_ds[1][1]._xs, full_ds[1][1]._ys\n",
    "np.shape(step_hk(params, key1, xs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
