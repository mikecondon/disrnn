{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disentangled RNNs for Mouse Switching Dataset\n",
    "The dataset below is from [Harvard Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/7E0NM5). Each row corresponds to a trial, and the columns correspond to the trial number, block position, target direction, choice direction, and reward outcome, as well as the session and mouse identifiers and task conditions.\n",
    "\n",
    "| Trial | blockTrial | Decision | Switch | Reward | Condition | Target | blockLength | Session | Mouse |\n",
    "|-------|------------|----------|--------|--------|-----------|--------|-------------|---------|-------|\n",
    "| 11.0  | 11.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |\n",
    "| 12.0  | 12.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |\n",
    "| 13.0  | 13.0       | 1.0      | 0.0    | 1.0    | 90-10     | 1.0    | 58.0        | m1_77   | m1    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangled_rnns.library import rnn_utils\n",
    "from disentangled_rnns.library import disrnn\n",
    "from disentangled_rnns import switch_utils\n",
    "import optax\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "addr = \"/Users/michaelcondon/workspaces/pbm_group2/2ABT_behavior_models/bandit_data.csv\"\n",
    "batch_size = 30\n",
    "test_prop = 0.7\n",
    "df = pd.read_csv(addr)\n",
    "\n",
    "# shuffle the sessions\n",
    "eps = df['Session'].value_counts().sample(frac=1)\n",
    "\n",
    "# create training and validation datasets with a 70% train 30% validation split\n",
    "tr_eps = eps.iloc[:math.floor(test_prop*len(eps))]\n",
    "tr_eps.name = \"training_sessions\"\n",
    "ds_tr = switch_utils.get_dataset(df[df['Session'].isin(tr_eps.index)], batch_size)\n",
    "\n",
    "va_eps = eps.iloc[math.floor(test_prop*len(eps)):]\n",
    "va_eps.name = \"validation_sessions\"\n",
    "ds_va = switch_utils.get_dataset(df[df['Session'].isin(va_eps.index)], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_mlp_shape = (5,5,5)\n",
    "choice_mlp_shape = (2,2)\n",
    "latent_size = 5\n",
    "\n",
    "def make_network():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "opt = optax.adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Iterate through the mice, and through the beta values, saving the trained\n",
    "params and loss for each in a json to disk.\n",
    "\"\"\"\n",
    "betas = [1e-3]\n",
    "# betas = [1e-3]\n",
    "n_steps = 1e4\n",
    "\n",
    "n_calls = len(betas)\n",
    "dt = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "print(f\"start time: {dt}\")\n",
    "switch_utils.split_saver(tr_eps, va_eps, dt, test_prop)\n",
    "with tqdm(total=n_calls, desc='Overall Progress', position=1) as outer_bar:\n",
    "  for beta_j in betas:\n",
    "    outer_bar.set_postfix(beta=f\"{beta_j:.0e}\")\n",
    "    params, opt_state, losses = rnn_utils.train_network(\n",
    "    make_network,\n",
    "        ds_tr,\n",
    "        ds_va,\n",
    "        ltype_tr=\"penalized_categorical\",\n",
    "        opt = optax.adam(learning_rate),\n",
    "        penalty_scale = beta_j,\n",
    "        n_steps=n_steps,\n",
    "        do_plot = False)\n",
    "    switch_utils.model_saver(params, beta_j, dt=dt, loss=losses, test_prop=test_prop)\n",
    "    outer_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "From here on, you can load models from disk for each mouse as trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = \"/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/models/\"\n",
    "\n",
    "# choose mouse, beta and run time\n",
    "test_prop = 0.7\n",
    "cv = f'{test_prop*100:.0f}-{(1-test_prop)*100:.0f}'\n",
    "beta = 0.001\n",
    "dt = \"2025-04-10_12-51\"\n",
    "\n",
    "params_file = os.path.join(directory, f\"params_{beta:.0e}_{cv}_{dt}.json\")\n",
    "loss_file = os.path.join(directory, f\"loss_{beta:.0e}_{cv}_{dt}.json\")\n",
    "\n",
    "params, loss = switch_utils.model_loader(params_file=params_file, loss_file=loss_file)\n",
    "training_loss = loss['training_loss']\n",
    "validation_loss = loss['validation_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.semilogy(training_loss, color='black')\n",
    "plt.semilogy(np.linspace(0, len(training_loss), len(validation_loss)), validation_loss, color='tab:red', linestyle='dashed')\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Mean Loss')\n",
    "plt.legend(('Training Set', 'Validation Set'))\n",
    "plt.title('Loss over Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval mode runs the network with no noise\n",
    "def make_network_eval():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2,\n",
    "                        eval_mode=True)\n",
    "\n",
    "\n",
    "disrnn.plot_bottlenecks(params, sort_latents=True)\n",
    "plt.show()\n",
    "disrnn.plot_update_rules(params, make_network_eval)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Switching Analysis\n",
    "Here I will check how the RNN models from above behave from a switching perspective. This is based on the comparisons from the paper:\n",
    "\n",
    "    Beron, C. C., Neufeld, S. Q., Linderman, S. W., & Sabatini, B. L. (2022). Mice exhibit stochastic and efficient action switching during probabilistic decision making. Proceedings of the National Academy of Sciences, 119(15), e2113961119. https://doi.org/10.1073/pnas.2113961119\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_dict = switch_utils.switch_bars(ds_va._xs, ds_va._xs[:,:,0], symm=True, prob=True)\n",
    "\n",
    "sorted_items = sorted(p_dict.items(), key=lambda item: item[1])\n",
    "sorted_labels = [item[0] for item in sorted_items]\n",
    "sorted_heights = [item[1] for item in sorted_items]\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.7, rc={'axes.labelsize':20, 'axes.titlesize':20})\n",
    "sns.set_palette('deep')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,4.2))\n",
    "\n",
    "sns.barplot(x=sorted_labels, y=sorted_heights, color='k', alpha=0.5, ax=ax, edgecolor='gray')\n",
    "ax.errorbar(x=sorted_labels, y=sorted_heights, fmt=' ', color='k', label=None)\n",
    "\n",
    "ax.set(xlim=(-1,len(sorted_heights)), ylim=(0,1), ylabel='P(switch)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine()\n",
    "plt.title('Empirical Switch Probabilities')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# make_network_eval, step_hk and unroll_network are functions needed to use\n",
    "# the neural network.\n",
    "def make_network_eval():\n",
    "  return disrnn.HkDisRNN(update_mlp_shape=update_mlp_shape,\n",
    "                        choice_mlp_shape=choice_mlp_shape,\n",
    "                        latent_size=latent_size,\n",
    "                        obs_size=2, target_size=2,\n",
    "                        eval_mode=True)\n",
    "\n",
    "def unroll_network(xs):\n",
    "  core = make_network()\n",
    "  batch_size = jnp.shape(xs)[1]\n",
    "  state = core.initial_state(batch_size)\n",
    "  ys, _ = hk.dynamic_unroll(core, xs, state)\n",
    "  return ys\n",
    "\n",
    "\n",
    "_, step_hk = hk.transform(unroll_network)\n",
    "step_hk = jax.jit(step_hk)\n",
    "\n",
    "random_key = jax.random.PRNGKey(0)\n",
    "\n",
    "# first two columns give the probability of left and right (but need to be put through\n",
    "# softmax for normalising)\n",
    "output = step_hk(params, random_key, ds_va._xs)[:,:,:2]\n",
    "# sample from the output either greedily or with thompson sampling\n",
    "y_sampled = switch_utils.sampler(output, 'thompson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated conditional probability dictionary for each 3 letter history\n",
    "p_dict = switch_utils.switch_bars(ds_va._xs, ds_va._xs[:,:,0], symm=True, prob=True)\n",
    "sim_p_dict = switch_utils.switch_bars(ds_va._xs[1:], y_sampled[:-1,:], symm=True, prob=True)\n",
    "\n",
    "sorted_items = sorted(p_dict.items(), key=lambda item: item[1])\n",
    "sorted_keys = [item[0] for item in sorted_items] \n",
    "sorted_labels = [item[0] for item in sorted_items]\n",
    "sorted_heights = [item[1] for item in sorted_items]\n",
    "sim_sorted_heights = [sim_p_dict[key] for key in sorted_keys]\n",
    "\n",
    "sns.set(style='ticks', font_scale=1.7, rc={'axes.labelsize':20, 'axes.titlesize':20})\n",
    "sns.set_palette('deep')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14,4.2))\n",
    "\n",
    "sns.barplot(x=sorted_labels, y=sim_sorted_heights, color='g', alpha=1, ax=ax, label='DisRNN Switch Prob')\n",
    "sns.barplot(x=sorted_labels, y=sorted_heights, color='k', alpha=0.5, ax=ax, edgecolor='gray', label='Mouse Switch Prob')\n",
    "\n",
    "ax.set(xlim=(-1,len(sorted_heights)), ylim=(0,1), ylabel='P(switch)')\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine()\n",
    "plt.title('Empirical Switch Probabilities')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('/Users/michaelcondon/workspaces/pbm_group2/disentangled_rnns/figs/switch_probs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Analysis\n",
    "Here, I simulate sessions where the reward contingincies are first calculated independently of choices, then the choices are simulated. The trial length for each mouse is normally distributed with mean and std below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and std of trial length\n",
    "print(f\"trial length mean: {eps.mean():.2f}, std: {eps.std():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
